=== File: ./chat/chat_repository.go ===
Type: File
Extension: .go
Content:
package chat

import (
	"errors"
	"sync"
	"time"

	"github.com/google/uuid"
)

// Chat represents a chat in the repository.
type Chat struct {
	id        string
	name      string
	prompts   []Prompt
	createdAt time.Time
	updatedAt time.Time
}

// Prompt represents a prompt in a chat.
type Prompt struct {
	id        string
	text      string
	responses []Response
	createdAt time.Time
	updatedAt time.Time
}

func (p Prompt) Id() string {
	return p.id
}

// Response represents a response to a prompt.
type Response struct {
	id        string
	text      string
	createdAt time.Time
}

var (
	ErrChatNotFound   = errors.New("chat not found")
	ErrPromptNotFound = errors.New("prompt not found")
)

// ChatRepository manages the storage and retrieval of chats, prompts, and responses.
type ChatRepository struct {
	chats map[string]*Chat
	mu    sync.Mutex
}

// NewChatRepository creates a new ChatRepository.
func NewChatRepository() *ChatRepository {
	return &ChatRepository{
		chats: make(map[string]*Chat),
	}
}

// AddChat adds a new chat to the repository and returns its ID.
func (r *ChatRepository) AddChat(name string) string {
	r.mu.Lock()
	defer r.mu.Unlock()

	chat := &Chat{
		id:        uuid.New().String(),
		name:      name,
		prompts:   make([]Prompt, 0),
		createdAt: time.Now(),
		updatedAt: time.Now(),
	}

	r.chats[chat.id] = chat
	return chat.id
}

// GetChat retrieves a chat by its ID.
func (r *ChatRepository) GetChat(chatId string) (*Chat, error) {
	r.mu.Lock()
	defer r.mu.Unlock()

	chat, exists := r.chats[chatId]
	if !exists {
		return nil, ErrChatNotFound
	}

	return chat, nil
}

// RenameChat updates the name of an existing chat.
func (r *ChatRepository) RenameChat(chatId, newName string) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	chat, exists := r.chats[chatId]
	if !exists {
		return ErrChatNotFound
	}

	chat.name = newName
	chat.updatedAt = time.Now()
	return nil
}

// DeleteChat removes a chat from the repository.
func (r *ChatRepository) DeleteChat(chatId string) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	_, exists := r.chats[chatId]
	if !exists {
		return ErrChatNotFound
	}

	delete(r.chats, chatId)
	return nil
}

// SubmitPrompt submits a prompt to a chat.
func (r *ChatRepository) SubmitPrompt(chatId, promptText string) (*Prompt, error) {
	r.mu.Lock()
	defer r.mu.Unlock()

	chat, exists := r.chats[chatId]
	if !exists {
		return nil, ErrChatNotFound
	}

	prompt := Prompt{
		id:        uuid.New().String(),
		text:      promptText,
		responses: make([]Response, 0),
		createdAt: time.Now(),
		updatedAt: time.Now(),
	}

	chat.prompts = append(chat.prompts, prompt)
	chat.updatedAt = time.Now()

	return &prompt, nil
}

// AddResponseToPrompt adds a response to a specific prompt in a chat.
func (r *ChatRepository) AddResponseToPrompt(chatId, promptId, responseText string) error {
	r.mu.Lock()
	defer r.mu.Unlock()

	chat, exists := r.chats[chatId]
	if !exists {
		return ErrChatNotFound
	}

	for i, prompt := range chat.prompts {
		if prompt.id == promptId {
			response := Response{
				id:        uuid.New().String(),
				text:      responseText,
				createdAt: time.Now(),
			}
			prompt.responses = append(prompt.responses, response)
			prompt.updatedAt = time.Now()
			chat.prompts[i] = prompt
			chat.updatedAt = time.Now()
			return nil
		}
	}

	return ErrPromptNotFound
}


=== File: ./chat/chat_service.go ===
Type: File
Extension: .go
Content:
package chat

import (
	"demo/pubsub"
	"log"
	"strings"
	"sync"
)

// ChatService orchestrates operations on chats, prompts, and responses.
type ChatService struct {
	repo   *ChatRepository
	pubSub *pubsub.PubSub
	mu     sync.Mutex
}

// NewChatService creates a new ChatService with the given repository and PubSub system.
func NewChatService(repo *ChatRepository, pubSub *pubsub.PubSub) *ChatService {
	return &ChatService{
		repo:   repo,
		pubSub: pubSub,
	}
}

// CreateChat creates a new chat and publishes a "ChatCreated" event.
func (s *ChatService) CreateChat(name string) string {
	s.mu.Lock()
	defer s.mu.Unlock()

	chatID := s.repo.AddChat(name)
	s.pubSub.Publish("ChatCreated", map[string]interface{}{
		"chatId": chatID,
		"name":   name,
	})

	return chatID
}

// RenameChat renames an existing chat and publishes an event.
func (s *ChatService) RenameChat(chatID, newName string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	err := s.repo.RenameChat(chatID, newName)
	if err != nil {
		return err
	}

	// Publish a "ChatRenamed" event.
	s.pubSub.Publish("ChatRenamed", map[string]interface{}{
		"chatId":  chatID,
		"newName": newName,
	})

	return nil
}

// DeleteChat deletes a chat and publishes an event.
func (s *ChatService) DeleteChat(chatID string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	err := s.repo.DeleteChat(chatID)
	if err != nil {
		return err
	}

	// Publish a "ChatDeleted" event.
	s.pubSub.Publish("ChatDeleted", map[string]interface{}{
		"chatId": chatID,
	})

	return nil
}

// SubmitPrompt submits a prompt, stores it in the repository, and publishes a "PromptSubmitted" event.
func (s *ChatService) SubmitPrompt(chatID, promptText string) (*Prompt, error) {
	s.mu.Lock()
	defer s.mu.Unlock()

	prompt, err := s.repo.SubmitPrompt(chatID, promptText)
	if err != nil {
		return nil, err
	}

	s.pubSub.Publish("PromptSubmitted", map[string]interface{}{
		"chatId":     chatID,
		"promptId":   prompt.id,
		"promptText": promptText,
	})

	return prompt, nil
}

// HandleTokensGenerated processes TokensGenerated events and updates the prompt with the response.
func (s *ChatService) HandleTokensGenerated(chatId, promptId, responseText string) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	// Append the token to the prompt's response.
	err := s.repo.AddResponseToPrompt(chatId, promptId, responseText)
	if err != nil {
		log.Printf("Error adding response to prompt: %v\n", err)
		return err
	}

	log.Printf("Token added to ChatID=%s, PromptID=%s: %s\n", chatId, promptId, responseText)
	return nil
}

// GetRecentAggregatedTokens retrieves the recent aggregated tokens as a sentence.
func (s *ChatService) GetRecentAggregatedTokens(chatId, promptId string) (string, error) {
	s.mu.Lock()
	defer s.mu.Unlock()

	chat, err := s.repo.GetChat(chatId)
	if err != nil {
		return "", err
	}

	for _, prompt := range chat.prompts {
		if prompt.id == promptId {
			var responseText strings.Builder
			for _, response := range prompt.responses {
				responseText.WriteString(response.text)
			}
			return responseText.String(), nil
		}
	}

	return "", ErrPromptNotFound
}

func (s *ChatService) ListenForTokensGenerated() <-chan string {
	tokenCh := make(chan string, 100)
	go func() {
		s.pubSub.Subscribe("TokensGenerated", func(payload interface{}) {
			data, ok := payload.(map[string]interface{})
			if !ok {
				log.Println("Invalid payload for TokensGenerated event")
				return
			}

			// Extract event data.
			chatID, ok := data["chatId"].(string)
			if !ok {
				log.Println("Invalid chatId in TokensGenerated event")
				return
			}

			promptID, ok := data["promptId"].(string)
			if !ok {
				log.Println("Invalid promptId in TokensGenerated event")
				return
			}

			responseText, ok := data["responseText"].(string)
			if !ok {
				log.Println("Invalid responseText in TokensGenerated event")
				return
			}

			go func() {
				// Send the response text to the token channel.
				tokenCh <- responseText
			}()

			// Handle the TokensGenerated event and send token to the channel.
			err := s.HandleTokensGenerated(chatID, promptID, responseText)
			if err != nil {
				log.Printf("Failed to handle TokensGenerated event: %v\n", err)
				return
			}

		})
	}()

	return tokenCh
}


=== File: ./prompt-processing/ollama-engine.go ===
Type: File
Extension: .go
Content:
package promptprocessing

import (
	"context"
	"fmt"
	"log"

	"github.com/tmc/langchaingo/llms"
	"github.com/tmc/langchaingo/llms/ollama"
)

// OllamaEngine implements the LLMEngineType interface using the Ollama model.
type OllamaEngine struct {
	model string
}

// NewOllamaEngine creates a new OllamaEngine with the specified model.
func NewOllamaEngine(model string) *OllamaEngine {
	return &OllamaEngine{
		model: model,
	}
}

// GenerateTokens generates tokens using the Ollama model and sends them through a channel.
func (o *OllamaEngine) GenerateTokens(ctx context.Context, prompt string) (<-chan string, error) {
	llm, err := ollama.New(ollama.WithModel(o.model))
	if err != nil {
		return nil, fmt.Errorf("failed to create Ollama LLM: %w", err)
	}

	tokenChan := make(chan string)

	go func() {
		defer close(tokenChan)

		_, err := llm.Call(ctx, prompt,
			llms.WithTemperature(0.8),
			llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
				tokenChan <- string(chunk)
				return nil
			}),
		)
		if err != nil {
			log.Printf("Error generating tokens: %v", err)
		}
	}()

	return tokenChan, nil
}


=== File: ./prompt-processing/prompt_processing_service.go ===
Type: File
Extension: .go
Content:
package promptprocessing

import (
	"context"
	"demo/pubsub"
	"log"
)

// LLMEngineType defines the interface for any LLM engine.
type LLMEngineType interface {
	GenerateTokens(ctx context.Context, prompt string) (<-chan string, error)
}

// PromptProcessingService handles processing prompts.
type PromptProcessingService struct {
	pubSub    *pubsub.PubSub
	llmEngine LLMEngineType
}

// NewPromptProcessingService creates a new PromptProcessingService with the given LLM engine.
func NewPromptProcessingService(pubSub *pubsub.PubSub, llmEngine LLMEngineType) *PromptProcessingService {
	return &PromptProcessingService{
		pubSub:    pubSub,
		llmEngine: llmEngine,
	}
}

// Start starts listening for "PromptSubmitted" events.
func (s *PromptProcessingService) Start() {
	s.pubSub.Subscribe("PromptSubmitted", func(payload interface{}) {
		data, ok := payload.(map[string]interface{})
		if !ok {
			log.Println("Invalid payload for PromptSubmitted event")
			return
		}

		// Extract event data.
		chatID := data["chatId"].(string)
		promptID := data["promptId"].(string)
		promptText := data["promptText"].(string)

		log.Printf("Processing prompt: ChatID=%s, PromptID=%s, Text=%s\n", chatID, promptID, promptText)

		// Generate tokens using the LLM engine.
		ctx := context.Background()
		tokenChan, err := s.llmEngine.GenerateTokens(ctx, promptText)
		if err != nil {
			log.Printf("Error generating tokens: %v", err)
			return
		}

		// Publish TokensGenerated events for each token.
		go func() {
			for token := range tokenChan {
				log.Printf("Generated token for ChatID=%s, PromptID=%s: %s\n", chatID, promptID, token)
				s.pubSub.Publish("TokensGenerated", map[string]interface{}{
					"chatId":       chatID,
					"promptId":     promptID,
					"responseText": token,
				})
			}
		}()
	})
}


=== File: ./index.html ===
Type: File
Extension: .html
Content:
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chat Application</title>
    
    <script src="https://unpkg.com/htmx.org@2.0.4"></script>
    <script src="https://unpkg.com/htmx-ext-sse@2.2.2/sse.js"></script>


</head>

<body>
    <h1>Chat Application</h1>

    <!-- Form for submitting a prompt -->
    <form hx-post="/prompt" hx-swap="none">
        <input type="text"  id="prompt"  name="prompt" placeholder="Enter your prompt..." required>
        <button type="submit">Submit</button>
    </form>




    <!-- Display streaming response -->
    <div id="stream-response" hx-get="/stream-component"  hx-trigger="PromptSubmitted from:body" hx-vals='js:{id: event.detail.id}'></div>



</body>

</html>

=== File: ./prompt.txt ===
Type: File
Extension: .txt
Content:

 #################
 My Requiremetns: 
 
 the  templ component is showing one token at all times, new token clears the past token, 

 I want to aggregate the tokens as they stream from the server

